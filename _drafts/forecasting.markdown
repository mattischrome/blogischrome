---
layout: post
title: "Forecasting"
categories: "Mathematics"
tags: [Maths, Stats, Coronavirus, Twenty]
date: "2020-06-07"
---

Humans have wanted to know the future for as long as there have been humans. There has been a lucrative market for predicting the future for almost as long. This market grows more in times of uncertainty, at least when risk is perceived. In the present moment of global uncertainty there is a high demand for knowledge of what the future will bring.

However, when useful information is rare, there are often unscrupulous operators in any market. It's the nature of capitalism (and capitalists) to exploit systems in which demand outstrips supply. We've seen it day after day in recent months. Some misinformation and bad advice springs from a lack of understanding and some of it is wilful brazen lies.

How do you tell the good from the bad? As ever, it's best to own the means of production. If your fate depends on knowing how the course of current events (and I'd hazard that it does) then you need to make your own predictions. You can then act accordingly, or at least understand why you might be prevented from acting the way that you want to. 

This is the first in a series of posts about forecasting. The series as a whole will focus on:

* What tools are available to us?
* How can we interpret predictions and forecasts?
* How do these same predictions and forecasts depend upon assumptions and data?
* How can we reduce our dependence on predictions?

I have some experience in making predictions for a living. I admit that if my predictions were that good I might not be writing this post. However, I hope I can explain the forecasting process, so that you can understand how they can be interpreted and interrogated. I'm using these posts are to expand the range of techniques I use to make predictions. As a result, I am going to be learning too! This may mean that I skip over some topics that I feel confident in, and I might even get some stuff all wrong if it's new to me. If you're reading along and spot any issues, please do get in touch. A transparent and public way to do so would be to [raise an issue on this site's GitHub repo][1], but you can also tweet at me [(@mattischrome)][2].

I will not focus all my examples on epidemics. Understanding forecasting requires us to look at many examples of where we might need a forecast, so we can assess what data are available to us and begin to ask questions of that data. We also need to ask questions that go beyond simply what we are forecasting: such as the purpose of the forecast and what we would do in possession of an accurate forecast.

Of course, “accurate forecast” is a loaded term, as forecasting often has a built-in survival bias. You remember forecasts that are roughly correct or use hindsight bias to rationalise as to why a given prediction was correct, even if it wasn't really so. You also remember forecasts that are wildly wrong, especially if they cause you a personal hinderance. We don't care when the weather is better than was predicted, but often curse when we get caught out. 

Emotion can also cloud our interpretation of and response to predictions. The more that accuracy is critical to achieving success (or avoiding failure), the more likely it is you are going to be disappointed. One of the weird and beautiful meta-facts about forecasting is that the more wrong you are allowed to be, the better your prediction is likely to be. 

Caveats are essential to forecasts. Forecasters use caveats the way artisans use detailing, as a demonstration of skill and craftsmanship. At first they can seem like excuses for why your forecast won't ring true. In fact allow forecasters to highlight the areas where they are most confident in the forecast and where potential flaws might be. Forecasting, prediction, and modelling are not one-shot processes, but an iteration that should use all the data, methods and time available to the forecaster.



[1]:	https://github.com/mattischrome/blogischrome/issues
[2]:	https://twitter.com/mattischrome/